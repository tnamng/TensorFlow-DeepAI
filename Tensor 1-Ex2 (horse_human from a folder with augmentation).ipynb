{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensor 1-Ex2 (horse/human from a folder).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nCAAnqZaV667"},"source":["## 1. Load Data"]},{"cell_type":"code","metadata":{"id":"m-3qGmlGVvZG"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n","    -O /tmp/horse-or-human.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVIsU6EIVxv0"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n","    -O /tmp/validation-horse-or-human.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnehLCEWV0-F"},"source":["import os\n","import zipfile\n","\n","local_zip = '/tmp/horse-or-human.zip'\n","with zipfile.ZipFile(local_zip,\"r\") as zip_ref:\n","    zip_ref.extractall('/tmp/horse-or-human')\n","    \n","local_zip = '/tmp/validation-horse-or-human.zip'\n","with zipfile.ZipFile(local_zip,\"r\") as zip_ref:\n","    zip_ref.extractall('/tmp/validation-horse-or-human')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SlgdiMg-WAGQ"},"source":["## 2. Model"]},{"cell_type":"code","metadata":{"id":"49eOCRH6WBLG"},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqt42MgkWFW0"},"source":["model = keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n","    # This is the first convolution\n","    keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    #tf.keras.layers.MaxPooling2D(2,2),\n","    # The fifth convolution\n","    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    #tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    keras.layers.Flatten(),\n","    # 512 neuron hidden layer\n","    keras.layers.Dense(512, activation='relu'),\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.summary()\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=keras.optimizers.RMSprop(lr=0.001),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eD1hawGXWaQu"},"source":["## 3. Data Processing (simple case)"]},{"cell_type":"code","metadata":{"id":"TOLIh-oPWc9w"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","validation_datagen = ImageDataGenerator(rescale=1/255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/horse-or-human/',  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=128,\n","        class_mode='binary')\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","validation_generator = validation_datagen.flow_from_directory(\n","        '/tmp/validation-horse-or-human/',  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=32,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0X4YjiOJWxxa"},"source":["## 4. Fit and history"]},{"cell_type":"code","metadata":{"id":"TQOUvM02Wfay"},"source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,  \n","      epochs=15,\n","      verbose=1,\n","      validation_data = validation_generator,\n","      validation_steps=8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5WbOo_gWiFH"},"source":["pd.DataFrame(history.history()).plot()"],"execution_count":null,"outputs":[]}]}