{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensor 2-Ex2 [transferlearning].ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NHkXIE3NlFKE"},"source":["# 1. Load pretrained model"]},{"cell_type":"code","metadata":{"id":"DQEZDTLClFKQ"},"source":["import os\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n","    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBPTh7YxSM4J"},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n","                                include_top = False, \n","                                weights = None)\n","\n","pre_trained_model.load_weights(local_weights_file)\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","  \n","# pre_trained_model.summary()\n","\n","last_layer = pre_trained_model.get_layer('mixed7')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RpOLPiASYkU"},"source":["\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","x = layers.Dense(1024, activation='relu')(x)\n","x = layers.Dropout(0.2)(x)                  \n","x = layers.Dense  (1, activation='sigmoid')(x)           \n","\n","model = Model(pre_trained_model.input, x) \n","\n","model.compile(optimizer = tensorflow.keras.optimizers.RMSprop(lr=0.0001), \n","              loss = 'binary_crossentropy', \n","              metrics = ['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQMC_1oelFKS"},"source":["# 2. Load data (cat/dogs)"]},{"cell_type":"code","metadata":{"id":"8xTIkDEMlFKS"},"source":["!wget --no-check-certificate \\\n","        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","       -O /tmp/cats_and_dogs_filtered.zip\n","\n","\n","import os\n","import zipfile\n","\n","local_zip = '//tmp/cats_and_dogs_filtered.zip'\n","with zipfile.ZipFile(local_zip, 'r') as zip_ref\n","    zip_ref.extractall('/tmp')\n","\n","\n","# Define our example directories and files\n","base_dir = '/tmp/cats_and_dogs_filtered'\n","\n","train_dir = os.path.join( base_dir, 'train')\n","validation_dir = os.path.join( base_dir, 'validation')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l-s-mmUslFKT"},"source":["# 3. Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"uAl9GPwUlFKT"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                   rotation_range = 40,\n","                                   width_shift_range = 0.2,\n","                                   height_shift_range = 0.2,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    batch_size = 20,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (150, 150))     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  test_datagen.flow_from_directory( validation_dir,\n","                                                          batch_size  = 20,\n","                                                          class_mode  = 'binary', \n","                                                          target_size = (150, 150))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-n-_tWwflFKU"},"source":["# 4. Fit and history"]},{"cell_type":"code","metadata":{"id":"aQXQPc05XSNU"},"source":["history = model.fit(\n","            train_generator,\n","            validation_data = validation_generator,\n","            steps_per_epoch = 100,\n","            epochs = 20,\n","            validation_steps = 50,\n","            verbose = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFVYHfmgXPyV"},"source":["pd.DataFrame(history.history)[['loss','val_loss']].plot()\n","plt.figure()\n","pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()"],"execution_count":null,"outputs":[]}]}