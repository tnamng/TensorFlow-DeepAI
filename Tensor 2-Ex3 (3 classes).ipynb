{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Tensor 2-Ex3 (3 classes).ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%208%20-%20Lesson%202%20-%20Notebook%20(RockPaperScissors).ipynb","timestamp":1612951133459}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FRGprTSAZKvt"},"source":["### 1. Load datasets"]},{"cell_type":"code","metadata":{"id":"it1c0jCiNCIM"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \\\n","    -O /tmp/rps.zip\n","  \n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip \\\n","    -O /tmp/rps-test-set.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnYP_HhYNVUK"},"source":["import os\n","import zipfile\n","\n","local_zip = '/tmp/rps.zip'\n","with zipfile.ZipFile(local_zip, 'r') as zip_ref: \n","    zip_ref.extractall('/tmp/')\n","\n","local_zip = '/tmp/rps-test-set.zip'\n","with zipfile.ZipFile(local_zip, 'r') as zip_ref: \n","    zip_ref.extractall('/tmp/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9y5_rTbvZVvQ"},"source":["### 2. Data preprocessing (Augmentation) "]},{"cell_type":"code","metadata":{"id":"LWTisYLQM1aM"},"source":["import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","\n","\n","training_datagen = ImageDataGenerator(\n","      rescale = 1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale = 1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukRNbFxwniG6"},"source":["TRAINING_DIR = \"/tmp/rps/\"\n","VALIDATION_DIR = \"/tmp/rps-test-set/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7V7wGjXEniG7"},"source":["train_generator = training_datagen.flow_from_directory(\n","    TRAINING_DIR,\n","    target_size=(150,150),\n","    class_mode='categorical',\n","    batch_size=126\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    VALIDATION_DIR,\n","    target_size=(150,150),\n","    class_mode='categorical',\n","    batch_size=126\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VgnpXhE1niG7"},"source":["# 3. Our model"]},{"cell_type":"code","metadata":{"id":"5L-FAYWqniG7"},"source":["model = tf.keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","model.summary()\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","history = model.fit(train_generator, \n","                    epochs=25, steps_per_epoch=20, \n","                    validation_data = validation_generator, verbose = 1, validation_steps=3)\n","\n","model.save(\"rps.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeTRVCr6aosw"},"source":["pd.DataFrame(history.history)[['loss','val_loss']].plot()\n","plt.figure()\n","pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()"],"execution_count":null,"outputs":[]}]}