{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf]","language":"python","name":"conda-env-tf-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Remark.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"4sqcp8KPfTej"},"source":["import os\n","import zipfile\n","\n","local_zip = '/tmp/cats_and_dogs_filtered.zip'\n","with zipfile.ZipFile(local_zip, 'r') as zip_ref\n","    zip_ref.extractall('/tmp')\n","    \n","base_dir = '/tmp/cats_and_dogs_filtered'\n","\n","train_dir = os.path.join( base_dir, 'train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lc273hlxfVVo"},"source":["import json\n","\n","with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBEgR3pzfTe0"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5O4uL0MfTe1"},"source":["#train_datagen = ImageDataGenerator(\n","#      rescale=1./255,\n","#      rotation_range=40,\n","#      width_shift_range=0.2,\n","#      height_shift_range=0.2,\n","#      shear_range=0.2,\n","#      zoom_range=0.2,\n","#      horizontal_flip=True,\n","#      fill_mode='nearest')\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    batch_size=20,\n","                                                    class_mode='binary'/'categorical',\n","                                                    target_size=(150, 150)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHlE2djsfTe1"},"source":["# II. XXXX"]},{"cell_type":"code","metadata":{"id":"_BfMpf4gfTe2"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEIk3lQJfTe2"},"source":["# number 1\n","tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","# number 2\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded = pad_sequences(sequences, maxlen=5, )  # padding='pre'/'post'   truncating = 'pre'/'post'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2U5P-FqfTe3"},"source":["III. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OekJdZemfTe4"},"source":["....io ..."],"execution_count":null,"outputs":[]}]}